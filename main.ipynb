{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "# os.chdir(os.path.join(os.getcwd(), \"titanic data\"))\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "full_df = pd.concat([train, test])\n",
    "print(len(full_df.index), len(train.index), len(test.index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "# there are some ages missing. Let's replace those with the mean\n",
    "mean_age = full_df[\"Age\"].mean() # mean age\n",
    "\n",
    "# Fill missing values in column A with the mean\n",
    "train[\"Age\"] = train[\"Age\"].fillna(mean_age)  # maybe it would be better to have it draw from a normal dist w those characteristics?\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(full_df[\"Embarked\"].value_counts().index[0])  # replace missing embarked with most common\n",
    "\n",
    "# do same for test data\n",
    "test[\"Age\"] = train[\"Age\"].fillna(mean_age)\n",
    "test[\"Embarked\"] = train[\"Embarked\"].fillna(full_df[\"Embarked\"].value_counts().index[0])\n",
    "\n",
    "print(train.info())\n",
    "print(test.info())\n",
    "\n",
    "# still need to figure out how cabin fits into this, and what to do about the nulls\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "# there's a fare missing from test dataset. I'll put the average fare in as a replacement\n",
    "test[\"Fare\"] = train[\"Fare\"].fillna(full_df[\"Fare\"].mean())\n",
    "test.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "\n",
    "train.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "# I want to visualize numeric variables with histograms\n",
    "numeric_cols = train.describe().columns\n",
    "\n",
    "for col in numeric_cols[1:]:  # exclude first element because visualizing passengerid is not helpful\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "no_id = train.drop([\"PassengerId\"], axis=1)\n",
    "sns.heatmap(no_id[numeric_cols[1:]].corr(), annot=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "categorical_cols = ['Survived','Pclass','Sex','Ticket','Cabin','Embarked']\n",
    "# print(categorical_cols)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(train[categorical_cols][col].value_counts().index, train[categorical_cols][col].value_counts())\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "# let's do a simple test where we don't account for any categorical variables\n",
    "to_drop = categorical_cols + [\"PassengerId\", \"Survived\", \"Name\"]\n",
    "x_train1_feed = train.drop(to_drop, axis=1)\n",
    "y_train1_feed = train[\"Survived\"]\n",
    "print(x_train1_feed.columns)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_train1_feed, y_train1_feed, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "# building first neural network to try\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"ReLU\"),\n",
    "    # tf.keras.layers.Dense(5, activation=\"ReLU\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# compile\n",
    "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history1 = model1.fit(x_train1, y_train1, epochs=200, verbose=0)\n",
    "\n",
    "print(model1.evaluate(x_test1, y_test1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "pd.DataFrame(history1.history).plot()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "# let's try a better one now and deal with categorical variables\n",
    "\n",
    "# turn sex into 1 and 0. now we can feed it to the model\n",
    "train[\"Sex\"] = train[\"Sex\"].map(lambda sex: int(sex == \"male\"))\n",
    "test[\"Sex\"] = test[\"Sex\"].map(lambda sex: int(sex == \"male\"))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "# one hot encode embarked\n",
    "embarked_dummies_train = pd.get_dummies(train[\"Embarked\"], prefix=\"Embarked\") # one-hot encode the embarked column using pd.get_dummies\n",
    "train = pd.concat([train, embarked_dummies_train], axis=1) # concatenate the one-hot encoded column with the original dataframe\n",
    "train = train.drop(\"Embarked\", axis=1)\n",
    "\n",
    "# same for test\n",
    "embarked_dummies_test = pd.get_dummies(test[\"Embarked\"], prefix=\"Embarked\") # one-hot encode the embarked column using pd.get_dummies\n",
    "test = pd.concat([test, embarked_dummies_test], axis=1) # concatenate the one-hot encoded column with the original dataframe\n",
    "test = test.drop(\"Embarked\", axis=1)\n",
    "# print(train)\n",
    "# print(test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "# what can be done with these three? Titles can be dealt with\n",
    "remaining_cat = ['Ticket','Cabin', \"Name\"]\n",
    "\n",
    "\n",
    "# not sure what can be done with cabin or titles\n",
    "print(train[\"Cabin\"].info())\n",
    "print(train[\"Cabin\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dealing with names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "# need to make a function to get name and convert to title\n",
    "def title_helper(name):\n",
    "    as_list = name.split(\" \")\n",
    "    for i, word in enumerate(as_list):\n",
    "        if word[-1] == \",\":\n",
    "            return as_list[i + 1]\n",
    "    else:\n",
    "        return name  # great, this wasn't needed!\n",
    "\n",
    "train[\"Title\"] = train[\"Name\"].apply(lambda x: title_helper(x))\n",
    "\n",
    "\n",
    "test[\"Title\"] = test[\"Name\"].apply(lambda x: title_helper(x))\n",
    "# print(train[\"Title\"].value_counts())\n",
    "# print(test[\"Title\"].value_counts())\n",
    "\n",
    "def merge_title_helper(title):\n",
    "    if title in [\"Don.\", \"Major.\", \"Capt.\", \"Jonkheer.\", \"Rev.\", \"Col.\", \"Dr.\", \"the\", \"Sir.\"]: # there's 1 \"the\". I didn't actually check if it's a man\n",
    "        return \"Mr.\"\n",
    "    elif title in [\"Countess.\", \"Mme.\", \"Dona.\", \"Lady.\"]:\n",
    "        return \"Mrs.\"\n",
    "    elif title in [\"Mlle.\", \"Ms.\"]:\n",
    "        return \"Miss.\"\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "train[\"Title\"] = train[\"Title\"].apply(lambda x: merge_title_helper(x))\n",
    "test[\"Title\"] = test[\"Title\"].apply(lambda x: merge_title_helper(x))\n",
    "\n",
    "# drop names now\n",
    "train = train.drop([\"Name\"], axis=1)\n",
    "test = test.drop([\"Name\"], axis=1)\n",
    "\n",
    "print(train[\"Title\"].value_counts())\n",
    "print(test[\"Title\"].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "# one hot encode titles\n",
    "title_dummies_train = pd.get_dummies(train[\"Title\"], prefix=\"Title\") # one-hot encode the title column using pd.get_dummies\n",
    "train = pd.concat([train, title_dummies_train], axis=1) # concatenate the one-hot encoded column with the original dataframe\n",
    "train = train.drop(\"Title\", axis=1)\n",
    "\n",
    "# same for test\n",
    "title_dummies_test = pd.get_dummies(test[\"Title\"], prefix=\"Title\")\n",
    "test = pd.concat([test, title_dummies_test], axis=1)\n",
    "test = test.drop(\"Title\", axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lets try building a better neural network after this additional preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "# train test split\n",
    "# print(train.columns)\n",
    "to_drop = [\"Cabin\", \"Ticket\", \"Survived\", \"PassengerId\"]\n",
    "x_train2_feed = train.drop(to_drop, axis=1)\n",
    "y_train2_feed = train[\"Survived\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_train2_feed, y_train2_feed, test_size=0.2, random_state=1)\n",
    "print(x_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "# building second neural network to try\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# compile\n",
    "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# fit\n",
    "history2 = model2.fit(x_train2, y_train2, epochs=100, verbose=1)\n",
    "print(\"--\")\n",
    "# print(model2.evaluate(x_test2, y_test2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "pd.DataFrame(history2.history).plot()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
